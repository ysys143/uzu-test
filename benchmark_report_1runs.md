# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14 (10 performance and 4 efficiency)
- **메모리**: 36 GB
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3

## 벤치마크 정보
- **실행 시간**: 2025-07-18T13:36:24.719144
- **반복 횟수**: 1회
- **테스트 프롬프트**: 10개
- **최대 토큰**: 50개
- **총 실행 횟수**: 40회

## 성능 요약

| 엔진 | 평균 TPS | TPS범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 8.67 | 7.2-9.4 | 0.63 | 1.0x |
| Ollama (GGUF) | 77.02 | 71.4-82.0 | 3.44 | 8.9x |
| llama.cpp (GGUF + Metal) | 2382.95 | 2161.4-2906.8 | 234.47 | 274.8x |
| Uzu (Native Metal) | 29.18 | 25.4-33.3 | 2.75 | 3.4x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 8.67
- 중간값: 8.75
- 최소값: 7.18
- 최대값: 9.42
- 표준편차: 0.63

**추론 시간 (초)**
- 평균: 5.796
- 중간값: 5.713
- 최소값: 5.309
- 최대값: 6.964
- 표준편차: 0.468

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 77.02
- 중간값: 77.81
- 최소값: 71.36
- 최대값: 82.03
- 표준편차: 3.44

**추론 시간 (초)**
- 평균: 6.949
- 중간값: 5.992
- 최소값: 2.564
- 최대값: 12.716
- 표준편차: 3.724

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 2382.95
- 중간값: 2299.56
- 최소값: 2161.45
- 최대값: 2906.83
- 표준편차: 234.47

**추론 시간 (초)**
- 평균: 1.672
- 중간값: 1.582
- 최소값: 1.549
- 최대값: 2.501
- 표준편차: 0.291

### Uzu (Native Metal)

**TPS (Tokens Per Second)**
- 평균: 29.18
- 중간값: 28.80
- 최소값: 25.39
- 최대값: 33.33
- 표준편차: 2.75

**추론 시간 (초)**
- 평균: 5.531
- 중간값: 5.198
- 최소값: 3.178
- 최대값: 7.231
- 표준편차: 1.507

## 테스트 프롬프트

1. "파이썬에서 리스트와 튜플의 차이점은?"
2. "HTTP와 HTTPS의 차이점을 설명해주세요."
3. "Git과 GitHub의 차이점은?"
4. "머신러닝과 딥러닝의 차이는?"
5. "파이썬에서 효율적인 데이터 처리를 위한 라이브러리들과 각각의 특징을 설명해주세요."
6. "소프트웨어 개발에서 테스트 주도 개발(TDD)의 장점과 실제 적용 방법은?"
7. "DevOps 문화와 도구들이 소프트웨어 개발에 미치는 영향을 설명해주세요."
8. "현대 웹 개발의 전체 스택을 구성하는 기술들과 각 계층별 역할, 그리고 최신 트렌드를 종합적으로 설명해주세요."
9. "인공지능과 머신러닝 기술이 다양한 산업 분야에 미치는 영향과 구체적인 활용 사례들, 그리고 향후 발전 방향과 고려해야 할 윤리적 이슈들을 설명해주세요."
10. "게임 개발에서 사용되는 엔진들의 특징과 그래픽스 파이프라인, 물리 엔진, AI 시스템 구현 방법, 그리고 최적화 기법들을 개발 단계별로 설명해주세요."

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 8.67 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 77.02 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 2382.95 |

### Uzu (Native Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 29.18 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 2382.95 TPS (274.8x)
2. **Ollama (GGUF)**: 77.02 TPS (8.9x)
3. **Uzu (Native Metal)**: 29.18 TPS (3.4x)
4. **PyTorch + MPS**: 8.67 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.63 TPS
2. **Uzu (Native Metal)**: 표준편차 2.75 TPS
3. **Ollama (GGUF)**: 표준편차 3.44 TPS
4. **llama.cpp (GGUF + Metal)**: 표준편차 234.47 TPS

---

*벤치마크 실행 시간: 2025-07-18T13:36:24.719144*
*생성된 파일: benchmark_results_multi_run_1.json*
