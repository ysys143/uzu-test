# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14개 (성능 코어 10개 + 효율 코어 4개)
- **메모리**: 36GB 통합 메모리
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3
  

## 벤치마크 정보
- **실행 시간**: 2025-07-17T18:49:22.699521
- **반복 횟수**: 1회
- **테스트 프롬프트**: 5개
- **최대 토큰**: 50개
- **총 실행 횟수**: 20회

## 성능 요약

| 엔진 | 평균 TPS | TPS 범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 8.16 | 7.0-9.1 | 0.80 | 1.0x |
| Ollama (GGUF) | 74.82 | 71.6-82.2 | 4.29 | 9.2x |
| llama.cpp (GGUF + Metal) | 322.08 | 161.3-448.3 | 117.28 | 39.5x |
| Uzu (Native Metal) | 75.22 | 70.7-82.4 | 5.16 | 9.2x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 8.16
- 중간값: 8.20
- 최소값: 6.97
- 최대값: 9.09
- 표준편차: 0.80

**추론 시간 (초)**
- 평균: 6.063
- 중간값: 6.096
- 최소값: 5.501
- 최대값: 6.603
- 표준편차: 0.433

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 74.82
- 중간값: 74.02
- 최소값: 71.58
- 최대값: 82.20
- 표준편차: 4.29

**추론 시간 (초)**
- 평균: 9.730
- 중간값: 8.385
- 최소값: 2.260
- 최대값: 23.582
- 표준편차: 8.214

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 322.08
- 중간값: 312.86
- 최소값: 161.26
- 최대값: 448.26
- 표준편차: 117.28

**추론 시간 (초)**
- 평균: 1.788
- 중간값: 1.615
- 최소값: 1.596
- 최대값: 2.477
- 표준편차: 0.385

### Uzu (Native Metal)

**TPS (Tokens Per Second)**
- 평균: 75.22
- 중간값: 73.35
- 최소값: 70.67
- 최대값: 82.37
- 표준편차: 5.16

**추론 시간 (초)**
- 평균: 0.645
- 중간값: 0.666
- 최소값: 0.554
- 최대값: 0.720
- 표준편차: 0.066

## 테스트 프롬프트

1. "안녕하세요! 반갑습니다."
2. "배고프다. 점심메뉴 추천해줘."
3. "파이썬으로 간단한 웹서버 만드는 방법 알려줘."
4. "오늘 날씨가 좋은데 뭘 할까?"
5. "AI의 미래에 대해 어떻게 생각해?"

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 8.16 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 74.82 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 322.08 |

### Uzu (Native Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 75.22 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 322.08 TPS (39.5x)
2. **Uzu (Native Metal)**: 75.22 TPS (9.2x)
3. **Ollama (GGUF)**: 74.82 TPS (9.2x)
4. **PyTorch + MPS**: 8.16 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.80 TPS
2. **Ollama (GGUF)**: 표준편차 4.29 TPS
3. **Uzu (Native Metal)**: 표준편차 5.16 TPS
4. **llama.cpp (GGUF + Metal)**: 표준편차 117.28 TPS

---

*벤치마크 실행 시간: 2025-07-17T18:49:22.699521*
*생성된 파일: benchmark_results_multi_run_1.json*
