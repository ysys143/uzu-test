# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14개 (성능 코어 10개 + 효율 코어 4개)
- **메모리**: 36GB 통합 메모리
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3

## 벤치마크 정보
- **실행 시간**: 2025-07-17T19:26:57.182923
- **반복 횟수**: 10회
- **테스트 프롬프트**: 5개
- **최대 토큰**: 50개
- **총 실행 횟수**: 200회

## 성능 요약

| 엔진 | 평균 TPS | TPS 범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 8.92 | 7.5-9.5 | 0.47 | 1.0x |
| Ollama (GGUF) | 75.70 | 68.1-93.4 | 6.49 | 8.5x |
| llama.cpp (GGUF + Metal) | 355.83 | 171.8-540.0 | 101.98 | 39.9x |
| Uzu (Native Metal) | 76.40 | 65.3-87.6 | 7.15 | 8.6x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 8.92
- 중간값: 9.05
- 최소값: 7.53
- 최대값: 9.48
- 표준편차: 0.47

**추론 시간 (초)**
- 평균: 5.622
- 중간값: 5.527
- 최소값: 5.272
- 최대값: 6.641
- 표준편차: 0.318

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 75.70
- 중간값: 73.38
- 최소값: 68.10
- 최대값: 93.40
- 표준편차: 6.49

**추론 시간 (초)**
- 평균: 8.305
- 중간값: 7.483
- 최소값: 0.554
- 최대값: 23.429
- 표준편차: 6.211

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 355.83
- 중간값: 360.61
- 최소값: 171.84
- 최대값: 540.03
- 표준편차: 101.98

**추론 시간 (초)**
- 평균: 1.584
- 중간값: 1.568
- 최소값: 1.347
- 최대값: 2.407
- 표준편차: 0.142

### Uzu (Native Metal)

**TPS (Tokens Per Second)**
- 평균: 76.40
- 중간값: 75.46
- 최소값: 65.26
- 최대값: 87.55
- 표준편차: 7.15

**추론 시간 (초)**
- 평균: 0.642
- 중간값: 0.640
- 최소값: 0.553
- 최대값: 0.734
- 표준편차: 0.053

## 테스트 프롬프트

1. "안녕하세요! 반갑습니다."
2. "배고프다. 점심메뉴 추천해줘."
3. "파이썬으로 간단한 웹서버 만드는 방법 알려줘."
4. "오늘 날씨가 좋은데 뭘 할까?"
5. "AI의 미래에 대해 어떻게 생각해?"

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 8.08 |
| 2 | 9.10 |
| 3 | 9.13 |
| 4 | 9.00 |
| 5 | 8.70 |
| 6 | 8.60 |
| 7 | 9.01 |
| 8 | 9.25 |
| 9 | 9.08 |
| 10 | 9.23 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 77.48 |
| 2 | 77.80 |
| 3 | 77.40 |
| 4 | 74.93 |
| 5 | 75.73 |
| 6 | 73.69 |
| 7 | 75.04 |
| 8 | 74.65 |
| 9 | 74.28 |
| 10 | 75.96 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 376.57 |
| 2 | 386.33 |
| 3 | 335.39 |
| 4 | 327.11 |
| 5 | 344.17 |
| 6 | 327.30 |
| 7 | 359.81 |
| 8 | 379.91 |
| 9 | 360.34 |
| 10 | 361.32 |

### Uzu (Native Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 74.99 |
| 2 | 73.90 |
| 3 | 74.78 |
| 4 | 73.31 |
| 5 | 81.61 |
| 6 | 82.77 |
| 7 | 72.61 |
| 8 | 77.73 |
| 9 | 74.38 |
| 10 | 77.92 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 355.83 TPS (39.9x)
2. **Uzu (Native Metal)**: 76.40 TPS (8.6x)
3. **Ollama (GGUF)**: 75.70 TPS (8.5x)
4. **PyTorch + MPS**: 8.92 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.47 TPS
2. **Ollama (GGUF)**: 표준편차 6.49 TPS
3. **Uzu (Native Metal)**: 표준편차 7.15 TPS
4. **llama.cpp (GGUF + Metal)**: 표준편차 101.98 TPS

---

*벤치마크 실행 시간: 2025-07-17T19:26:57.182923*
*생성된 파일: benchmark_results_multi_run_10.json*
