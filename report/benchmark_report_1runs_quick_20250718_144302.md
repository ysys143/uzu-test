# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14 (10 performance and 4 efficiency)
- **메모리**: 36 GB
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3

## 벤치마크 정보
- **실행 시간**: 2025-07-18T14:43:49.283216
- **반복 횟수**: 1회
- **테스트 프롬프트**: 1개
- **최대 토큰**: 500개
- **총 실행 횟수**: 4회

## 성능 요약

| 엔진 | 평균 TPS | TPS범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 7.45 | 7.5-7.5 | 0.00 | 1.0x |
| Ollama (GGUF) | 73.62 | 73.6-73.6 | 0.00 | 9.9x |
| llama.cpp (GGUF + Metal) | 2323.16 | 2323.2-2323.2 | 0.00 | 311.7x |
| Uzu (Native Metal) | 29.84 | 29.8-29.8 | 0.00 | 4.0x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 7.45
- 중간값: 7.45
- 최소값: 7.45
- 최대값: 7.45
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 26.164
- 중간값: 26.164
- 최소값: 26.164
- 최대값: 26.164
- 표준편차: 0.000

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 73.62
- 중간값: 73.62
- 최소값: 73.62
- 최대값: 73.62
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 3.488
- 중간값: 3.488
- 최소값: 3.488
- 최대값: 3.488
- 표준편차: 0.000

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 2323.16
- 중간값: 2323.16
- 최소값: 2323.16
- 최대값: 2323.16
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 4.301
- 중간값: 4.301
- 최소값: 4.301
- 최대값: 4.301
- 표준편차: 0.000

### Uzu (Native Metal)

**TPS (Tokens Per Second)**
- 평균: 29.84
- 중간값: 29.84
- 최소값: 29.84
- 최대값: 29.84
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 4.893
- 중간값: 4.893
- 최소값: 4.893
- 최대값: 4.893
- 표준편차: 0.000

## 테스트 프롬프트

1. "파이썬에서 리스트와 튜플의 차이점은?"

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 7.45 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 73.62 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 2323.16 |

### Uzu (Native Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 29.84 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 2323.16 TPS (311.7x)
2. **Ollama (GGUF)**: 73.62 TPS (9.9x)
3. **Uzu (Native Metal)**: 29.84 TPS (4.0x)
4. **PyTorch + MPS**: 7.45 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.00 TPS
2. **Ollama (GGUF)**: 표준편차 0.00 TPS
3. **llama.cpp (GGUF + Metal)**: 표준편차 0.00 TPS
4. **Uzu (Native Metal)**: 표준편차 0.00 TPS

---

*벤치마크 실행 시간: 2025-07-18T14:43:49.283216*
*JSON 데이터: output/benchmark_results_1runs_quick_20250718_144302.json*
*상세 로그: logging/benchmark_detailed_20250718_144302.log*
