# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14 (10 performance and 4 efficiency)
- **메모리**: 36 GB
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3

## 벤치마크 정보
- **실행 시간**: 2025-07-18T16:16:47.336547
- **반복 횟수**: 1회
- **테스트 프롬프트**: 1개
- **최대 토큰**: 500개
- **총 실행 횟수**: 3회

## 성능 요약

| 엔진 | 평균 TPS | TPS범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 7.04 | 7.0-7.0 | 0.00 | 1.0x |
| Ollama (GGUF) | 106.24 | 106.2-106.2 | 0.00 | 15.1x |
| llama.cpp (GGUF + Metal) | 125.93 | 125.9-125.9 | 0.00 | 17.9x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 7.04
- 중간값: 7.04
- 최소값: 7.04
- 최대값: 7.04
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 35.391
- 중간값: 35.391
- 최소값: 35.391
- 최대값: 35.391
- 표준편차: 0.000

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 106.24
- 중간값: 106.24
- 최소값: 106.24
- 최대값: 106.24
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 4.367
- 중간값: 4.367
- 최소값: 4.367
- 최대값: 4.367
- 표준편차: 0.000

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 125.93
- 중간값: 125.93
- 최소값: 125.93
- 최대값: 125.93
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 3.978
- 중간값: 3.978
- 최소값: 3.978
- 최대값: 3.978
- 표준편차: 0.000

## 테스트 프롬프트

1. "파이썬에서 리스트와 튜플의 차이점은?"

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 7.04 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 106.24 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 125.93 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 125.93 TPS (17.9x)
2. **Ollama (GGUF)**: 106.24 TPS (15.1x)
3. **PyTorch + MPS**: 7.04 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.00 TPS
2. **Ollama (GGUF)**: 표준편차 0.00 TPS
3. **llama.cpp (GGUF + Metal)**: 표준편차 0.00 TPS

---

*벤치마크 실행 시간: 2025-07-18T16:16:47.336547*
*JSON 데이터: output/benchmark_results_1runs_quick_20250718_161600.json*
*상세 로그: logging/benchmark_detailed_20250718_161600.log*
