# API 기반 추론 엔진 종합 성능 분석 리포트

## 📊 벤치마크 구성
- **실행 시간**: 2025-07-18T17:10:05.201820
- **모드**: 빠른 테스트
- **반복 횟수**: 1회
- **프롬프트 수**: 1개
- **최대 토큰**: 500개
- **온도 설정**: 0.3 (일관된 응답)
- **총 실행 횟수**: 4회

## 🚀 성능 요약

### 처리량 성능 (TPS)

| 순위 | 서버 | 평균 TPS | TPS 범위 | 표준편차 | 상대 성능 |
|------|------|----------|----------|----------|----------|
| 1위 | **Llamacpp Server** | 70.88 | 70.9-70.9 | 0.00 | **10.0x** |
| 2위 | **Ollama Server** | 67.35 | 67.4-67.4 | 0.00 | **9.5x** |
| 3위 | **Uzu Server** | 36.30 | 36.3-36.3 | 0.00 | **5.1x** |
| 4위 | **Pytorch Server** | 7.08 | 7.1-7.1 | 0.00 | **1.0x** |

### 응답 속도 성능 (Latency)

| 순위 | 서버 | 평균 Latency (초) | Latency 범위 | 표준편차 | 일관성 |
|------|------|-------------------|--------------|----------|--------|
| 1위 | **Ollama Server** | 3.445 | 3.44-3.44 | 0.000 | 높음 |
| 2위 | **Uzu Server** | 5.427 | 5.43-5.43 | 0.000 | 높음 |
| 3위 | **Llamacpp Server** | 7.054 | 7.05-7.05 | 0.000 | 높음 |
| 4위 | **Pytorch Server** | 33.618 | 33.62-33.62 | 0.000 | 높음 |

## 📈 상세 성능 통계

### Pytorch Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 7.08 | 7.08 | 7.08 | 7.08 | 0.00 |
| **Latency (초)** | 33.618 | 33.618 | 33.618 | 33.618 | 0.000 |

### Ollama Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 67.35 | 67.35 | 67.35 | 67.35 | 0.00 |
| **Latency (초)** | 3.445 | 3.445 | 3.445 | 3.445 | 0.000 |

### Llamacpp Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 70.88 | 70.88 | 70.88 | 70.88 | 0.00 |
| **Latency (초)** | 7.054 | 7.054 | 7.054 | 7.054 | 0.000 |

### Uzu Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 36.30 | 36.30 | 36.30 | 36.30 | 0.00 |
| **Latency (초)** | 5.427 | 5.427 | 5.427 | 5.427 | 0.000 |

## 🔍 성능 분석

### 성능 우수 서버

- **최고 처리량**: Llamacpp Server (70.88 TPS)
- **최단 응답시간**: Ollama Server (3.445초)

### 성능 안정성 분석

1. **Pytorch Server**: TPS 변동성 0.0%, Latency 변동성 0.0% (안정성: 높음)
2. **Ollama Server**: TPS 변동성 0.0%, Latency 변동성 0.0% (안정성: 높음)
3. **Llamacpp Server**: TPS 변동성 0.0%, Latency 변동성 0.0% (안정성: 높음)
4. **Uzu Server**: TPS 변동성 0.0%, Latency 변동성 0.0% (안정성: 높음)

## 🎯 시나리오별 권장 서버

### 처리량 우선 (API 서비스)
1. **Llamacpp Server**: 70.88 TPS, 7.1초 지연
2. **Ollama Server**: 67.35 TPS, 3.4초 지연
3. **Uzu Server**: 36.30 TPS, 5.4초 지연

### 응답속도 우선 (실시간 API)
1. **Ollama Server**: 3.445초 지연, 67.4 TPS
2. **Uzu Server**: 5.427초 지연, 36.3 TPS
3. **Llamacpp Server**: 7.054초 지연, 70.9 TPS

### 안정성 우선 (프로덕션 API)
1. **Pytorch Server**: 전체 변동성 0.0%
2. **Ollama Server**: 전체 변동성 0.0%
3. **Llamacpp Server**: 전체 변동성 0.0%

## 📋 종합 결론

**종합 성능 순위** (TPS와 Latency 균등 가중치)

1. **Ollama Server**: 종합 점수 0.975 (처리량: 0.950, 응답속도: 1.000)
2. **Llamacpp Server**: 종합 점수 0.744 (처리량: 1.000, 응답속도: 0.488)
3. **Uzu Server**: 종합 점수 0.573 (처리량: 0.512, 응답속도: 0.635)
4. **Pytorch Server**: 종합 점수 0.101 (처리량: 0.100, 응답속도: 0.102)

---

**데이터 파일**
- JSON 데이터: `output/api_benchmark_results_1runs_quick_20250718_170903.json`
- 상세 로그: `logging/api_benchmark_detailed_20250718_170903.log`

*리포트 생성 시간: 2025-07-18T17:10:05.201820*
