# API 기반 추론 엔진 종합 성능 분석 리포트

## 📊 벤치마크 구성
- **실행 시간**: 2025-07-18T17:34:52.703929
- **모드**: 정식 벤치마크
- **반복 횟수**: 3회
- **프롬프트 수**: 10개
- **최대 토큰**: 500개
- **온도 설정**: 0.3 (일관된 응답)
- **총 실행 횟수**: 120회

## 🚀 성능 요약

### 처리량 성능 (TPS)

| 순위 | 서버 | 평균 TPS | TPS 범위 | 표준편차 | 상대 성능 |
|------|------|----------|----------|----------|----------|
| 1위 | **Llamacpp Server** | 71.72 | 67.5-74.5 | 2.31 | **9.4x** |
| 2위 | **Ollama Server** | 71.42 | 43.8-75.7 | 5.44 | **9.3x** |
| 3위 | **Uzu Server** | 33.83 | 24.4-39.0 | 3.63 | **4.4x** |
| 4위 | **Pytorch Server** | 7.66 | 6.8-8.5 | 0.55 | **1.0x** |

### 응답 속도 성능 (Latency)

| 순위 | 서버 | 평균 Latency (초) | Latency 범위 | 표준편차 | 일관성 |
|------|------|-------------------|--------------|----------|--------|
| 1위 | **Ollama Server** | 4.055 | 2.21-6.95 | 1.514 | 보통 |
| 2위 | **Uzu Server** | 5.854 | 3.57-6.98 | 0.945 | 높음 |
| 3위 | **Llamacpp Server** | 6.271 | 1.48-7.34 | 1.480 | 보통 |
| 4위 | **Pytorch Server** | 39.573 | 23.20-68.25 | 16.848 | 보통 |

## 📈 상세 성능 통계

### Pytorch Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 7.66 | 7.55 | 6.85 | 8.49 | 0.55 |
| **Latency (초)** | 39.573 | 35.252 | 23.198 | 68.246 | 16.848 |

### Ollama Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 71.42 | 72.47 | 43.82 | 75.68 | 5.44 |
| **Latency (초)** | 4.055 | 3.544 | 2.205 | 6.954 | 1.514 |

### Llamacpp Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 71.72 | 72.55 | 67.47 | 74.53 | 2.31 |
| **Latency (초)** | 6.271 | 6.818 | 1.477 | 7.339 | 1.480 |

### Uzu Server

| 지표 | 평균 | 중간값 | 최소값 | 최대값 | 표준편차 |
|------|------|--------|--------|--------|---------|
| **TPS** | 33.83 | 34.65 | 24.38 | 39.05 | 3.63 |
| **Latency (초)** | 5.854 | 6.075 | 3.569 | 6.984 | 0.945 |

## 🔍 성능 분석

### 성능 우수 서버

- **최고 처리량**: Llamacpp Server (71.72 TPS)
- **최단 응답시간**: Ollama Server (4.055초)

### 성능 안정성 분석

1. **Llamacpp Server**: TPS 변동성 3.2%, Latency 변동성 23.6% (안정성: 보통)
2. **Uzu Server**: TPS 변동성 10.7%, Latency 변동성 16.1% (안정성: 보통)
3. **Ollama Server**: TPS 변동성 7.6%, Latency 변동성 37.3% (안정성: 보통)
4. **Pytorch Server**: TPS 변동성 7.2%, Latency 변동성 42.6% (안정성: 보통)

## 🎯 시나리오별 권장 서버

### 처리량 우선 (API 서비스)
1. **Llamacpp Server**: 71.72 TPS, 6.3초 지연
2. **Ollama Server**: 71.42 TPS, 4.1초 지연
3. **Uzu Server**: 33.83 TPS, 5.9초 지연

### 응답속도 우선 (실시간 API)
1. **Ollama Server**: 4.055초 지연, 71.4 TPS
2. **Uzu Server**: 5.854초 지연, 33.8 TPS
3. **Llamacpp Server**: 6.271초 지연, 71.7 TPS

### 안정성 우선 (프로덕션 API)
1. **Llamacpp Server**: 전체 변동성 13.4%
2. **Uzu Server**: 전체 변동성 13.4%
3. **Ollama Server**: 전체 변동성 22.5%

## 📋 종합 결론

**종합 성능 순위** (TPS와 Latency 균등 가중치)

1. **Ollama Server**: 종합 점수 0.998 (처리량: 0.996, 응답속도: 1.000)
2. **Llamacpp Server**: 종합 점수 0.823 (처리량: 1.000, 응답속도: 0.647)
3. **Uzu Server**: 종합 점수 0.582 (처리량: 0.472, 응답속도: 0.693)
4. **Pytorch Server**: 종합 점수 0.105 (처리량: 0.107, 응답속도: 0.102)

---

**데이터 파일**
- JSON 데이터: `output/api_benchmark_results_3runs_20250718_171920.json`
- 상세 로그: `logging/api_benchmark_detailed_20250718_171920.log`

*리포트 생성 시간: 2025-07-18T17:34:52.703929*
