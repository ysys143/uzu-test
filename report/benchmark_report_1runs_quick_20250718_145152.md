# Uzu AI 추론 엔진 성능 벤치마크 결과

## 시스템 정보
- **모델**: MacBook Pro (Mac15,10)
- **프로세서**: Apple M3 Max
- **CPU 코어**: 14 (10 performance and 4 efficiency)
- **메모리**: 36 GB
- **운영체제**: macOS 15.5 (24F74)
- **Python**: 3.12.3

## 벤치마크 정보
- **실행 시간**: 2025-07-18T14:52:33.652131
- **반복 횟수**: 1회
- **테스트 프롬프트**: 1개
- **최대 토큰**: 500개
- **총 실행 횟수**: 3회

## 성능 요약

| 엔진 | 평균 TPS | TPS범위 | 표준편차 | 상대 성능 |
|------|----------|----------|----------|----------|
| PyTorch + MPS | 7.31 | 7.3-7.3 | 0.00 | 1.0x |
| Ollama (GGUF) | 74.49 | 74.5-74.5 | 0.00 | 10.2x |
| llama.cpp (GGUF + Metal) | 2337.30 | 2337.3-2337.3 | 0.00 | 319.5x |

## 상세 통계

### PyTorch + MPS

**TPS (Tokens Per Second)**
- 평균: 7.31
- 중간값: 7.31
- 최소값: 7.31
- 최대값: 7.31
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 30.351
- 중간값: 30.351
- 최소값: 30.351
- 최대값: 30.351
- 표준편차: 0.000

### Ollama (GGUF)

**TPS (Tokens Per Second)**
- 평균: 74.49
- 중간값: 74.49
- 최소값: 74.49
- 최대값: 74.49
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 4.307
- 중간값: 4.307
- 최소값: 4.307
- 최대값: 4.307
- 표준편차: 0.000

### llama.cpp (GGUF + Metal)

**TPS (Tokens Per Second)**
- 평균: 2337.30
- 중간값: 2337.30
- 최소값: 2337.30
- 최대값: 2337.30
- 표준편차: 0.00

**추론 시간 (초)**
- 평균: 4.219
- 중간값: 4.219
- 최소값: 4.219
- 최대값: 4.219
- 표준편차: 0.000

## 테스트 프롬프트

1. "파이썬에서 리스트와 튜플의 차이점은?"

## 실행별 평균 TPS

### PyTorch + MPS

| 실행 | 평균 TPS |
|------|----------|
| 1 | 7.31 |

### Ollama (GGUF)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 74.49 |

### llama.cpp (GGUF + Metal)

| 실행 | 평균 TPS |
|------|----------|
| 1 | 2337.30 |

## 결론

**성능 순위 (평균 TPS 기준)**

1. **llama.cpp (GGUF + Metal)**: 2337.30 TPS (319.5x)
2. **Ollama (GGUF)**: 74.49 TPS (10.2x)
3. **PyTorch + MPS**: 7.31 TPS (1.0x)

**성능 안정성 (표준편차 기준)**

1. **PyTorch + MPS**: 표준편차 0.00 TPS
2. **Ollama (GGUF)**: 표준편차 0.00 TPS
3. **llama.cpp (GGUF + Metal)**: 표준편차 0.00 TPS

---

*벤치마크 실행 시간: 2025-07-18T14:52:33.652131*
*JSON 데이터: output/benchmark_results_1runs_quick_20250718_145152.json*
*상세 로그: logging/benchmark_detailed_20250718_145152.log*
